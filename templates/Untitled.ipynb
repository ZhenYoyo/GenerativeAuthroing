{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379435cf-85df-4e5d-8b14-08294e6483c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "<+  #systemprompt>you are a beautiful butterfly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you are a beautiful butterfly']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "<+  #sensorprompt> now, you should turn the story into something very happy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t> now, you should turn the story into something very happy']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "<+  #switching0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currentsystemprompt: you are a beautiful butterfly \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "<+  #playertext>I want to know more about the topic of bubble tea, please\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currentplayerinput: I want to know more about the topic of bubble tea, please \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "<+  #start0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currentsensorprompt: t> now, you should turn the story into something very happy \n",
      "\n",
      "narrator: Once upon a time in a bustling city, there was a charming bubble tea shop called \"Bubbly Bliss.\" This shop was renowned for its delicious and colorful bubble teas that brought joy to all who tasted them. The shop was owned by a friendly and talented young woman named Lily, who had a passion for creating unique and delightful flavors of bubble tea.\n",
      "\n",
      "Lily's shop was always filled with laughter and happiness as customers from all walks of life came to enjoy her refreshing drinks. The sound of the tapioca pearls popping in the straw and the sweet aroma of the teas filled the air, creating a cozy and inviting atmosphere.\n",
      "\n",
      "Lily took great pride in her craft, constantly experimenting with new ingredients and flavor combinations to surprise and delight her customers. She believed that each bubble tea she made had the power to brighten someone's day and spread a little bit of happiness.\n",
      "\n",
      "One day, a group of friends stumbled upon Bubbly Bliss and were instantly captivated by the array of colorful drinks on display. They eagerly tried different flavors and couldn't help but smile as they sipped on the delicious concoctions.\n",
      "\n",
      "As they sat around a table, chatting and laughing, they realized that it wasn't just the bubble tea that made them happy, but the warm and welcoming atmosphere of the shop and the passion that Lily poured into her creations.\n",
      "\n",
      "From that day on, the friends made it a tradition to visit Bubbly Bliss regularly, not just for the amazing bubble tea, but for the sense of joy and community that Lily had cultivated in her shop.\n",
      "\n",
      "And so, Bubbly Bliss became more than just a place to grab a drink - it became a place where people came together to share moments of happiness, friendship, and love, all thanks to the magical power of bubble tea. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "#currently we can apply our own key, but later need to public this to let user to put their own key\n",
    "openai.api_key = \"sk-f29A4tQuVfHMbdcgqHrNIF3QRVJmbpnrqucE7V7062r4fz8L\"\n",
    "openai.api_base = \"https://api.f2gpt.com/v1\"\n",
    "\n",
    "narratorsystemprompt= \"\"\n",
    "narratorsystempromptlist = []\n",
    "\n",
    "narratorsensorprompt=\"\"\n",
    "narratorsensorpromptlist=[]\n",
    "\n",
    "#this is for simulating the real text input from the player(not the user-author of the interactive narrative) . if the player input is empty, then the system will proceed through \"a viewing lense\"\n",
    "playerinput=\"\"\n",
    "\n",
    "\n",
    "class Agent():   \n",
    "    def __init__(self, agent_name, system_msg, assistant_msg, init_user_msg, respond_length):\n",
    "        self.agent_name = agent_name\n",
    "        self.system_msg = system_msg\n",
    "        self.assistant_msg = assistant_msg\n",
    "        self.init_user_msg = init_user_msg\n",
    "        self.respond_length = respond_length\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_msg},\n",
    "                         {\"role\": \"assistant\", \"content\": assistant_msg},\n",
    "                         {\"role\": \"user\", \"content\": init_user_msg}]\n",
    "        self.debug_mode = False \n",
    "\n",
    "    def get_completion(self, model=\"gpt-3.5-turbo\", temperature=0.8):\n",
    "        #global total_tokens\n",
    "        messages = self.messages\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message[\"content\"]})\n",
    "        self.total_tokens = response.usage[\"total_tokens\"]\n",
    "        #print(\"Total tokens:\", total_tokens)\n",
    "\n",
    "        if self.debug_mode:\n",
    "            #return response\n",
    "            return messages\n",
    "        else:\n",
    "            return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "#need to test directly modify the agent's system prompt or wake up a new agent\n",
    "narrator = Agent(\"narrator\", \n",
    "                  narratorsystemprompt,\n",
    "                  \"Hi, I'm the narrator.\", \n",
    "                  \"\", \n",
    "                  \"30\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    # listening to user input\n",
    "    user_input = input(\"<+ \")\n",
    "    \n",
    "    # skip if no real input\n",
    "    if not user_input:\n",
    "        continue\n",
    "\n",
    "#---FOR USER/AUTHOR. initial set up--define different system prompt and user prompt    \n",
    "    if user_input.startswith(\"#systemprompt>\"):\n",
    "     narratorsystempromptlist.append(user_input[14:])\n",
    "     print(narratorsystempromptlist)\n",
    "\n",
    "\n",
    "    if user_input.startswith(\"#sensorprompt>\"):\n",
    "     narratorsensorpromptlist.append(user_input[12:])\n",
    "     print(narratorsensorpromptlist)\n",
    "\n",
    "#---FOR PLAYER. for control live play,\n",
    "    #here is simulating the function of switching between different system prompt based on the narrative branching \n",
    "    #later should replace the text input method with the real condition\n",
    "    if user_input.startswith(\"#switching\"):\n",
    "        systempromptindex = user_input[10:]\n",
    "        if systempromptindex.isdigit() and int(systempromptindex) < len(narratorsystempromptlist):\n",
    "            narratorsystemprompt = narratorsystempromptlist[int(systempromptindex)]\n",
    "            print(\"currentsystemprompt:\", narratorsystemprompt, \"\\n\")\n",
    "\n",
    "    #here is simulating the input from the real player\n",
    "    if user_input.startswith(\"#playertext>\"):\n",
    "        playerinput = user_input[12:]\n",
    "        print(\"currentplayerinput:\", playerinput, \"\\n\")\n",
    "\n",
    "    #here is the conversation monitor\n",
    "    if user_input.startswith(\"#start\"):\n",
    "     sensorpromptindex = user_input[6:]\n",
    "     if sensorpromptindex.isdigit() and int(sensorpromptindex) < len(narratorsensorpromptlist):\n",
    "        narratorsensorprompt = narratorsensorpromptlist[int(sensorpromptindex)]\n",
    "        print(\"currentsensorprompt:\", narratorsensorprompt, \"\\n\")\n",
    "        narrator.debug_mode = False\n",
    "        narrator.messages.append({\"role\": \"system\", \"content\": narratorsystemprompt})\n",
    "        narrator.messages.append({\"role\": \"user\", \"content\": narratorsensorprompt + playerinput})\n",
    "        narrator_response = narrator.get_completion()\n",
    "        print(\"narrator:\", narrator_response, \"\\n\")\n",
    "     else:\n",
    "        print(\"Invalid index!\")\n",
    "\n",
    "    if user_input == \"DEBUG\":\n",
    "        narrator.debug_mode = True\n",
    "        narrator_response = narrator.get_completion()\n",
    "        print(\"\\n narratorhistory:\")\n",
    "        print(narrator_response)\n",
    "        narrator.debug_mode = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c72541-ef0c-4aa0-accc-ea4a5f78bcc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'OpenAI'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_BASE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m BASE_URL\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#-----\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#defining model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m ChatOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#-----\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#---\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#defining world setting, character, narrator behavior, input variables for differenve narrative stages--page1\u001b[39;00m\n\u001b[0;32m     32\u001b[0m narrator_behavior_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\load\\serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:1102\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:366\u001b[0m, in \u001b[0;36mChatOpenAI.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    350\u001b[0m client_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\n\u001b[0;32m    352\u001b[0m         values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_secret_value()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    363\u001b[0m }\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m values\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 366\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_params)\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m values\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync_client\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    368\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync_client\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mAsyncOpenAI(\n\u001b[0;32m    369\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_params\n\u001b[0;32m    370\u001b[0m     )\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'openai' has no attribute 'OpenAI'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "#------\n",
    "# ---- full debug\n",
    "#import langchain \n",
    "#langchain.debug = True\n",
    "#-------\n",
    "\n",
    "#-----\n",
    "#defining api key\n",
    "API_SECRET_KEY = \"sk-f29A4tQuVfHMbdcgqHrNIF3QRVJmbpnrqucE7V7062r4fz8L\"\n",
    "BASE_URL = \"https://api.f2gpt.com/v1\" \n",
    "os.environ[\"OPENAI_API_KEY\"] = API_SECRET_KEY\n",
    "os.environ[\"OPENAI_API_BASE\"] = BASE_URL\n",
    "#-----\n",
    "#defining model\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", verbose=True)\n",
    "#-----\n",
    "\n",
    "#---\n",
    "#defining world setting, character, narrator behavior, input variables for differenve narrative stages--page1\n",
    "narrator_behavior_list = []\n",
    "input_variables_list = []\n",
    "input_variables_demonstration = []\n",
    "narrative_retrieval_list = []\n",
    "\n",
    "#---\n",
    "# for page 2, template state machine\n",
    "prompttemplate_list = []\n",
    "formatted_retrieval_list = []\n",
    "currentprompt = \"\"\n",
    "\n",
    "#----\n",
    "#this should not be changes, is for summarizing the chat history -- page3\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "#for switching stages\n",
    "stage = 0\n",
    "\n",
    "#------\n",
    "\n",
    "\n",
    "\n",
    "# for page-2 to 3, add new item to RunnableParallel\n",
    "class RunnableParallel:\n",
    "    def __init__(self, items):\n",
    "        self.items = items\n",
    "\n",
    "    def add_item(self, key, value):\n",
    "        self.items[key] = value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    user_input = input(\"<+ \")\n",
    "\n",
    "    if not user_input:\n",
    "        continue\n",
    "\n",
    "\n",
    "    #-----PAGE1\n",
    "    #adding the narrative setting and character\n",
    "\n",
    "    if user_input.startswith(\"world>\"):\n",
    "      narrative_retrieval_list.append(\"worldsetting:\"+user_input[6:] + \"\\n\")\n",
    "      print(\"narrative_retrieval_list:\", narrative_retrieval_list)\n",
    "    if user_input.startswith(\"character>\"):\n",
    "      narrative_retrieval_list.append(\"character:\"+ user_input[10:]+ \"\\n\")\n",
    "      print(\"narrative_retrieval_list:\", narrative_retrieval_list)\n",
    "\n",
    "    #adding narrator behaviors\n",
    "    if user_input.startswith(\"narratorbehavior>\"):\n",
    "        narrator_behavior_list.append(user_input[17:]+ \"\\n\")\n",
    "        print(\"narrator_behavior_list:\", narrator_behavior_list)\n",
    "\n",
    "\n",
    "    #adding input variables and their functions\n",
    "    if user_input.startswith(\"inputvariable>\"):\n",
    "        #input must be in the form of \"{lightintensity} is changing the emotional tone of the story\", {lightintensity} is the input variable\n",
    "        new_input_variable = user_input[14:]\n",
    "        input_variables_list.append(new_input_variable)\n",
    "        description = input(\"defining this input:\")\n",
    "        input_variables_demonstration.append(\"{\"+new_input_variable+\"}\"+ description)\n",
    "        print(\"input_variables_list:\", input_variables_list)\n",
    "        print(\"input_variables_demonstration:\", input_variables_demonstration)\n",
    "\n",
    "    #-----PAGE2\n",
    "    # defining the combinations for different narrative stages\n",
    "    #! 这里有一个问题是现在的1, 2 是写定的, 要想怎么跟按钮联系起来, 按下按钮之后添加一个input stage/ 或者或多个input stage-- 可能是list同时多个item的问题\n",
    "    if user_input.startswith(\"branching>\"):   \n",
    "        inputstage1_index = int(input(\"input_stage1:\"))\n",
    "        inputstage1 = input_variables_list[inputstage1_index] \n",
    "        inputstage1_demonstration = input_variables_demonstration[inputstage1_index]\n",
    "\n",
    "        inputstage2_index = int(input(\"input_stage2:\"))\n",
    "        inputstage2 = input_variables_list[inputstage2_index] \n",
    "        inputstage2_demonstration = input_variables_demonstration[inputstage2_index]\n",
    "\n",
    "        #put numer here, 0 for picking out the first item from the list\n",
    "        #！这里有点问题, 理论上要支持添加多个narrative elements, 但是这里只支持每次给一个阶段的narrative添加一条\n",
    "        narrative_1 = narrative_retrieval_list[int(input(\"narrative_1:\"))]\n",
    "        narrative_2 = narrative_retrieval_list[int(input(\"narrative_2:\"))]\n",
    "\n",
    "        prompttemplate_list.insert(0, narrator_behavior_list[0] + \"This is the story context you are based from:{context} \\ generate narrative based on player's input: {question}. \" + inputstage1_demonstration)\n",
    "        formatted_retrieval_list.insert(0, narrative_1)\n",
    "        \n",
    "        prompttemplate_list.insert(1, narrator_behavior_list[1] + \"This is the story context you are based from:{context} \\ generate narrative based on player's input: {question}. \" + inputstage2_demonstration)\n",
    "        formatted_retrieval_list.insert(1, narrative_2)\n",
    "\n",
    "        print(\"prompttemplate_list:\", prompttemplate_list)\n",
    "        print(\"formatted_retrieval_list:\", formatted_retrieval_list)\n",
    "        #print(\"inputstage1:\", inputstage1, \"inputstage2:\", inputstage2, \"narrative_1:\", narrative_1, \"narrative_2:\", narrative_2)\n",
    "\n",
    "        \n",
    "        \n",
    " \n",
    "\n",
    "\n",
    "    #-----PAGE3\n",
    "    #run the game-page3\n",
    "        \n",
    "    #simulating narrative stage 1\n",
    "    if user_input.startswith(\"start>\"):\n",
    "    #-------\n",
    "    #docs/file/retrieval -- load and embedding knowledge for world setting and character\n",
    "        vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "        formatted_retrieval_list[stage],\n",
    "        embedding=OpenAIEmbeddings(),\n",
    "        )\n",
    "        retriever = vectorstore.as_retriever()\n",
    "    #-- ----\n",
    "        while True:\n",
    "            question = input(\"Player: \")\n",
    "\n",
    "            #will change based on the types of input chose before\n",
    "            currentinput = input_variables_list[stage]\n",
    "            currentinput_value= input(currentinput+\":\")\n",
    "            print(currentinput, currentinput_value)\n",
    "            \n",
    "            if question == \"switchstage\":\n",
    "                 stage = input(int(\"narrative stage:\"))\n",
    "    \n",
    "                 vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "                 # narrative_retrieval_list,\n",
    "                 formatted_retrieval_list[stage],\n",
    "                 embedding=OpenAIEmbeddings(),\n",
    "                 )   \n",
    "                 retriever = vectorstore.as_retriever()\n",
    "            \n",
    "            contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                (\"system\", contextualize_q_system_prompt),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{question}\"),\n",
    "                ]\n",
    "            )\n",
    "            contextualize_q_chain = contextualize_q_prompt | model | StrOutputParser()\n",
    "            #-----\n",
    "\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                (\"system\", prompttemplate_list[stage]),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{question}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "\n",
    "            def contextualized_question(input: dict):\n",
    "                if input.get(\"chat_history\"):\n",
    "                    return contextualize_q_chain\n",
    "                else:\n",
    "                    return input[\"question\"]\n",
    "\n",
    "\n",
    "            #!!!###   \n",
    "            setup_and_retrieval = RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "            setup_and_retrieval.add_item(currentinput, RunnablePassthrough())\n",
    "\n",
    "            rag_chain = (\n",
    "                RunnablePassthrough.assign(\n",
    "                context=contextualized_question | retriever \n",
    "            )\n",
    "                | prompt\n",
    "                | model\n",
    "            )\n",
    "\n",
    "\n",
    "            invoke_dict = {\"question\": question, \"chat_history\": chat_history}\n",
    "            invoke_dict[currentinput] =  currentinput_value # 添加新的键值对\n",
    "            \n",
    "            #ai_msg = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "            ai_msg = rag_chain.invoke(invoke_dict)\n",
    "            chat_history.extend([HumanMessage(content=question), AIMessage(content=ai_msg.content)])\n",
    "            print(\"narrative:\", ai_msg.content)\n",
    "            #print if check the chat history\n",
    "            #print(\"chat history:\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d2df08-b7eb-430b-9faf-a96eee775f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Openai in c:\\users\\user\\anaconda3\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from Openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\anaconda3\\lib\\site-packages (from Openai) (3.8.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.20->Openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.20->Openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.20->Openai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.20->Openai) (2024.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->Openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->Openai) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->Openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->Openai) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->Openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->Openai) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->Openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4780261b-6443-4c1f-8421-d77fc25f4612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
